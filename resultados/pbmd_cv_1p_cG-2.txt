4 5
Starting read from Train file...
(5320, 6)
train.shape = (5320, 4)
train_labels.shape = (5320, 1)
(5264, 4) (56, 4)

******************************************************
Decision Tree:

0.660714285714
[[ 0 17  0]
 [ 0 37  0]
 [ 0  2  0]]

******************************************************
Gaussian Naive Bayes:

0.0178571428571
[[ 0  0  0  0]
 [50  1  4  1]
 [ 0  0  0  0]
 [ 0  0  0  0]]

******************************************************
KNN:
---------------------
KNN ==  5 :

0.660714285714
[[ 0  0]
 [19 37]]
---------------------
KNN ==  9 :

0.571428571429
[[ 0  0]
 [24 32]]
---------------------
KNN ==  11 :

0.553571428571
[[ 0  0]
 [25 31]]
---------------------
KNN ==  13 :

0.410714285714
[[ 0  0  0]
 [32 23  1]
 [ 0  0  0]]

******************************************************
SVM:
grid.fit
Fitting 3 folds for each of 90 candidates, totalling 270 fits
{'kernel': 'rbf', 'C': 8.0, 'gamma': 0.0001220703125}
SVC(C=8.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.0001220703125,
  kernel='rbf', max_iter=-1, probability=True, random_state=None,
  shrinking=True, tol=0.001, verbose=False)

0.714285714286

******************************************************
Perceptron:

0.339285714286
[[ 0  0  0  0]
 [34 19  2  1]
 [ 0  0  0  0]
 [ 0  0  0  0]]

******************************************************
LDA:

0.267857142857
[[ 0  0]
 [41 15]]

******************************************************
Logistic Regression - ovr:

0.321428571429
[[ 0  0  0]
 [37 18  1]
 [ 0  0  0]]

******************************************************
Logistic Regression - mul:

0.303571428571
[[ 0  0  0]
 [37 17  2]
 [ 0  0  0]]
######################################################
(5122, 4) (198, 4)

******************************************************
Decision Tree:

0.282828282828
[[ 0 68  0  0  0]
 [ 0 56  0  0  0]
 [ 0 18  0  0  0]
 [ 0  6  0  0  0]
 [ 0 50  0  0  0]]

******************************************************
Gaussian Naive Bayes:

0.0
[[  0   0   0   0   0]
 [122   0  57  11   8]
 [  0   0   0   0   0]
 [  0   0   0   0   0]
 [  0   0   0   0   0]]

******************************************************
KNN:
---------------------
KNN ==  5 :

0.20202020202
[[ 0  0  0  0  0]
 [81 40 20  4 53]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]
---------------------
KNN ==  9 :

0.171717171717
[[ 0  0  0  0  0]
 [82 34 19  4 59]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]
---------------------
KNN ==  11 :

0.186868686869
[[ 0  0  0  0  0]
 [83 37 21  3 54]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]
---------------------
KNN ==  13 :

0.181818181818
[[ 0  0  0  0  0]
 [82 36 18  3 59]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]

******************************************************
SVM:
grid.fit
Fitting 3 folds for each of 90 candidates, totalling 270 fits
{'kernel': 'rbf', 'C': 8.0, 'gamma': 0.0001220703125}
SVC(C=8.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.0001220703125,
  kernel='rbf', max_iter=-1, probability=True, random_state=None,
  shrinking=True, tol=0.001, verbose=False)

0.151515151515

******************************************************
Perceptron:

0.0454545454545
[[ 0  0  0  0  0]
 [65  9 23  9 92]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]

******************************************************
LDA:

0.212121212121
[[  0   0   0   0   0]
 [120  42   2   2  32]
 [  0   0   0   0   0]
 [  0   0   0   0   0]
 [  0   0   0   0   0]]

******************************************************
Logistic Regression - ovr:

0.247474747475
[[ 0  0  0  0  0]
 [96 49  4  2 47]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]

******************************************************
Logistic Regression - mul:

0.262626262626
[[ 0  0  0  0  0]
 [89 52  7  2 48]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]
######################################################
(5242, 4) (78, 4)

******************************************************
Decision Tree:

0.423076923077
[[ 0  6  0  0  0]
 [ 0 33  0  0  0]
 [ 0  9  0  0  0]
 [ 0  6  0  0  0]
 [ 0 24  0  0  0]]

******************************************************
Gaussian Naive Bayes:

0.025641025641
[[ 0  0  0  0  0]
 [19  2 38 13  6]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]

******************************************************
KNN:
---------------------
KNN ==  5 :

0.538461538462
[[ 0  0  0  0  0]
 [ 3 42 10  9 14]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]
---------------------
KNN ==  9 :

0.448717948718
[[ 0  0  0  0  0]
 [ 2 35 12  6 23]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]
---------------------
KNN ==  11 :

0.410256410256
[[ 0  0  0  0  0]
 [ 3 32 13  5 25]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]
---------------------
KNN ==  13 :

0.346153846154
[[ 0  0  0  0  0]
 [ 3 27 12  6 30]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]

******************************************************
SVM:
grid.fit
Fitting 3 folds for each of 90 candidates, totalling 270 fits
{'kernel': 'rbf', 'C': 32.0, 'gamma': 0.0001220703125}
SVC(C=32.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.0001220703125,
  kernel='rbf', max_iter=-1, probability=True, random_state=None,
  shrinking=True, tol=0.001, verbose=False)

0.346153846154

******************************************************
Perceptron:

0.679487179487
[[ 0  0  0]
 [ 3 53 22]
 [ 0  0  0]]

******************************************************
LDA:

0.346153846154
[[ 0  0  0  0  0]
 [ 9 27 11  5 26]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]

******************************************************
Logistic Regression - ovr:

0.371794871795
[[ 0  0  0  0  0]
 [ 5 29 10  5 29]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]

******************************************************
Logistic Regression - mul:

0.371794871795
[[ 0  0  0  0  0]
 [ 3 29 11  5 30]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]
######################################################
(5163, 4) (157, 4)

******************************************************
Decision Tree:

0.229299363057
[[ 0 11  0  0  0]
 [ 0 36  0  0  0]
 [ 0 19  0  0  0]
 [ 0 66  0  0  0]
 [ 0 25  0  0  0]]

******************************************************
Gaussian Naive Bayes:

0.0
[[  0   0   0   0   0]
 [ 24   0  22 104   7]
 [  0   0   0   0   0]
 [  0   0   0   0   0]
 [  0   0   0   0   0]]

******************************************************
KNN:
---------------------
KNN ==  5 :

0.273885350318
[[ 0  0  0  0  0]
 [12 43 17 71 14]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]
---------------------
KNN ==  9 :

0.203821656051
[[ 0  0  0  0  0]
 [12 32 21 73 19]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]
---------------------
KNN ==  11 :

0.178343949045
[[ 0  0  0  0  0]
 [13 28 21 77 18]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]
---------------------
KNN ==  13 :

0.165605095541
[[ 0  0  0  0  0]
 [14 26 20 84 13]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]

******************************************************
SVM:
grid.fit
Fitting 3 folds for each of 90 candidates, totalling 270 fits
{'kernel': 'rbf', 'C': 32.0, 'gamma': 0.0001220703125}
SVC(C=32.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.0001220703125,
  kernel='rbf', max_iter=-1, probability=True, random_state=None,
  shrinking=True, tol=0.001, verbose=False)

0.15923566879

******************************************************
Perceptron:

0.031847133758
[[  0   0   0]
 [  6   5 146]
 [  0   0   0]]

******************************************************
LDA:

0.165605095541
[[ 0  0  0  0  0]
 [20 26 15 77 19]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]

******************************************************
Logistic Regression - ovr:

0.197452229299
[[ 0  0  0  0  0]
 [20 31  9 82 15]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]

******************************************************
Logistic Regression - mul:

0.133757961783
[[ 0  0  0  0  0]
 [20 21 22 81 13]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]
######################################################
(5224, 4) (96, 4)

******************************************************
Decision Tree:

0.625
[[ 0  0  9  0  0]
 [ 0  0  3  0  0]
 [ 0  0 60  0  0]
 [ 0  0 19  0  0]
 [ 0  0  5  0  0]]

******************************************************
Gaussian Naive Bayes:

0.520833333333
[[50 19 27]
 [ 0  0  0]
 [ 0  0  0]]

******************************************************
KNN:
---------------------
KNN ==  5 :

0.71875
[[ 0  0  0  0]
 [ 5 69 18  4]
 [ 0  0  0  0]
 [ 0  0  0  0]]
---------------------
KNN ==  9 :

0.75
[[ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 1  1 72 17  5]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]
---------------------
KNN ==  11 :

0.739583333333
[[ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 1  1 71 18  5]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]
---------------------
KNN ==  13 :

0.75
[[ 0  0  0  0]
 [ 1 72 18  5]
 [ 0  0  0  0]
 [ 0  0  0  0]]

******************************************************
SVM:
grid.fit
Fitting 3 folds for each of 90 candidates, totalling 270 fits
{'kernel': 'rbf', 'C': 8.0, 'gamma': 0.0001220703125}
SVC(C=8.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.0001220703125,
  kernel='rbf', max_iter=-1, probability=True, random_state=None,
  shrinking=True, tol=0.001, verbose=False)

0.770833333333

******************************************************
Perceptron:

0.239583333333
[[ 0  0  0]
 [67 23  6]
 [ 0  0  0]]

******************************************************
LDA:

0.625
[[ 0  0  0  0]
 [ 1 60 28  7]
 [ 0  0  0  0]
 [ 0  0  0  0]]

******************************************************
Logistic Regression - ovr:

0.552083333333
[[ 0  0  0  0]
 [ 1 53 35  7]
 [ 0  0  0  0]
 [ 0  0  0  0]]

******************************************************
Logistic Regression - mul:

0.635416666667
[[ 0  0  0  0]
 [ 1 61 27  7]
 [ 0  0  0  0]
 [ 0  0  0  0]]
######################################################
(5175, 4) (145, 4)

******************************************************
Decision Tree:

0.165517241379
[[ 0  0 59  0]
 [ 0  0 30  0]
 [ 0  0 24  0]
 [ 0  0 32  0]]

******************************************************
Gaussian Naive Bayes:

0.158620689655
[[  0   0   0   0   0]
 [  0   0   0   0   0]
 [114   5  23   1   2]
 [  0   0   0   0   0]
 [  0   0   0   0   0]]

******************************************************
KNN:
---------------------
KNN ==  5 :

0.124137931034
[[ 0  0  0  0]
 [ 0  0  0  0]
 [79 27 18 21]
 [ 0  0  0  0]]
---------------------
KNN ==  9 :

0.0896551724138
[[ 0  0  0  0]
 [ 0  0  0  0]
 [79 26 13 27]
 [ 0  0  0  0]]
---------------------
KNN ==  11 :

0.0689655172414
[[ 0  0  0  0]
 [ 0  0  0  0]
 [80 30 10 25]
 [ 0  0  0  0]]
---------------------
KNN ==  13 :

0.0620689655172
[[ 0  0  0  0]
 [ 0  0  0  0]
 [85 31  9 20]
 [ 0  0  0  0]]

******************************************************
SVM:
grid.fit
Fitting 3 folds for each of 90 candidates, totalling 270 fits
{'kernel': 'rbf', 'C': 32.0, 'gamma': 0.0001220703125}
SVC(C=32.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.0001220703125,
  kernel='rbf', max_iter=-1, probability=True, random_state=None,
  shrinking=True, tol=0.001, verbose=False)

0.0896551724138

******************************************************
Perceptron:

0.620689655172
[[ 0  0  0  0]
 [ 0  0  0  0]
 [50  1 90  4]
 [ 0  0  0  0]]

******************************************************
LDA:

0.00689655172414
[[  0   0   0   0]
 [  0   0   0   0]
 [107  36   1   1]
 [  0   0   0   0]]

******************************************************
Logistic Regression - ovr:

0.00689655172414
[[ 0  0  0  0]
 [ 0  0  0  0]
 [99 38  1  7]
 [ 0  0  0  0]]

******************************************************
Logistic Regression - mul:

0.00689655172414
[[ 0  0  0  0]
 [ 0  0  0  0]
 [98 40  1  6]
 [ 0  0  0  0]]
######################################################
(5130, 4) (190, 4)

******************************************************
Decision Tree:

0.447368421053
[[ 0  0 16  0  0]
 [ 0  0 26  0  0]
 [ 0  0 85  0  0]
 [ 0  0 27  0  0]
 [ 0  0 36  0  0]]

******************************************************
Gaussian Naive Bayes:

0.705263157895
[[  0   0   0   0]
 [ 33 134  17   6]
 [  0   0   0   0]
 [  0   0   0   0]]

******************************************************
KNN:
---------------------
KNN ==  5 :

0.715789473684
[[  0   0   0   0   0]
 [  0   0   0   0   0]
 [  8  18 136   6  22]
 [  0   0   0   0   0]
 [  0   0   0   0   0]]
---------------------
KNN ==  9 :

0.710526315789
[[  0   0   0   0   0]
 [  0   0   0   0   0]
 [  6  19 135   9  21]
 [  0   0   0   0   0]
 [  0   0   0   0   0]]
---------------------
KNN ==  11 :

0.705263157895
[[  0   0   0   0   0]
 [  0   0   0   0   0]
 [  4  19 134   9  24]
 [  0   0   0   0   0]
 [  0   0   0   0   0]]
---------------------
KNN ==  13 :

0.736842105263
[[  0   0   0   0   0]
 [  0   0   0   0   0]
 [  4  18 140   6  22]
 [  0   0   0   0   0]
 [  0   0   0   0   0]]

******************************************************
SVM:
grid.fit
Fitting 3 folds for each of 90 candidates, totalling 270 fits
{'kernel': 'rbf', 'C': 32.0, 'gamma': 0.0001220703125}
SVC(C=32.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.0001220703125,
  kernel='rbf', max_iter=-1, probability=True, random_state=None,
  shrinking=True, tol=0.001, verbose=False)

0.763157894737

******************************************************
Perceptron:

0.0
[[  0   0   0]
 [175   0  15]
 [  0   0   0]]

******************************************************
LDA:

0.747368421053
[[  0   0   0   0   0]
 [  0   0   0   0   0]
 [  6  10 142  15  17]
 [  0   0   0   0   0]
 [  0   0   0   0   0]]

******************************************************
Logistic Regression - ovr:

0.621052631579
[[  0   0   0   0   0]
 [  0   0   0   0   0]
 [ 19  13 118  15  25]
 [  0   0   0   0   0]
 [  0   0   0   0   0]]

******************************************************
Logistic Regression - mul:

0.757894736842
[[  0   0   0   0   0]
 [  0   0   0   0   0]
 [  2  13 144   8  23]
 [  0   0   0   0   0]
 [  0   0   0   0   0]]
######################################################
(5190, 4) (130, 4)

******************************************************
Decision Tree:

0.761538461538
[[ 0  0  6  0  0]
 [ 0  0  1  0  0]
 [ 0  0 99  0  0]
 [ 0  0 21  0  0]
 [ 0  0  3  0  0]]

******************************************************
Gaussian Naive Bayes:

0.615384615385
[[80 14 36]
 [ 0  0  0]
 [ 0  0  0]]

******************************************************
KNN:
---------------------
KNN ==  5 :

0.846153846154
[[  0   0   0   0]
 [  0   0   0   0]
 [  1   1 110  18]
 [  0   0   0   0]]
---------------------
KNN ==  9 :

0.9
[[117  13]
 [  0   0]]
---------------------
KNN ==  11 :

0.892307692308
[[116  14]
 [  0   0]]
---------------------
KNN ==  13 :

0.892307692308
[[116  14]
 [  0   0]]

******************************************************
SVM:
grid.fit
Fitting 3 folds for each of 90 candidates, totalling 270 fits
{'kernel': 'rbf', 'C': 32.0, 'gamma': 0.0001220703125}
SVC(C=32.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.0001220703125,
  kernel='rbf', max_iter=-1, probability=True, random_state=None,
  shrinking=True, tol=0.001, verbose=False)

0.884615384615

******************************************************
Perceptron:

0.0
[[  0   0]
 [130   0]]

******************************************************
LDA:

0.830769230769
[[  0   0   0]
 [  2 108  20]
 [  0   0   0]]

******************************************************
Logistic Regression - ovr:

0.792307692308
[[  0   0   0   0]
 [  2 103  24   1]
 [  0   0   0   0]
 [  0   0   0   0]]

******************************************************
Logistic Regression - mul:

0.876923076923
[[  0   0   0   0]
 [  2 114  13   1]
 [  0   0   0   0]
 [  0   0   0   0]]
######################################################
(5213, 4) (107, 4)

******************************************************
Decision Tree:

0.570093457944
[[ 0  0 29  0]
 [ 0  0  4  0]
 [ 0  0 61  0]
 [ 0  0 13  0]]

******************************************************
Gaussian Naive Bayes:

0.990654205607
[[  0   0]
 [  1 106]]

******************************************************
KNN:
---------------------
KNN ==  5 :

0.691588785047
[[ 0  0  0  0]
 [ 0  0  0  0]
 [28  1 74  4]
 [ 0  0  0  0]]
---------------------
KNN ==  9 :

0.691588785047
[[ 0  0  0]
 [31 74  2]
 [ 0  0  0]]
---------------------
KNN ==  11 :

0.747663551402
[[ 0  0  0]
 [26 80  1]
 [ 0  0  0]]
---------------------
KNN ==  13 :

0.766355140187
[[ 0  0  0]
 [23 82  2]
 [ 0  0  0]]

******************************************************
SVM:
grid.fit
Fitting 3 folds for each of 90 candidates, totalling 270 fits
{'kernel': 'rbf', 'C': 32.0, 'gamma': 0.0001220703125}
SVC(C=32.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.0001220703125,
  kernel='rbf', max_iter=-1, probability=True, random_state=None,
  shrinking=True, tol=0.001, verbose=False)

0.803738317757

******************************************************
Perceptron:

0.317757009346
[[ 0  0  0]
 [69 34  4]
 [ 0  0  0]]

******************************************************
LDA:

0.607476635514
[[ 0  0  0]
 [ 9 65 33]
 [ 0  0  0]]

******************************************************
Logistic Regression - ovr:

0.700934579439
[[ 0  0  0]
 [12 75 20]
 [ 0  0  0]]

******************************************************
Logistic Regression - mul:

0.738317757009
[[ 0  0  0]
 [14 79 14]
 [ 0  0  0]]
######################################################
(5229, 4) (91, 4)

******************************************************
Decision Tree:

0.56043956044
[[ 0  0  0  6  0]
 [ 0  0  0  9  0]
 [ 0  0  0 14  0]
 [ 0  0  0 51  0]
 [ 0  0  0 11  0]]

******************************************************
Gaussian Naive Bayes:

0.802197802198
[[ 0  0  0]
 [15 73  3]
 [ 0  0  0]]

******************************************************
KNN:
---------------------
KNN ==  5 :

0.67032967033
[[ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 2  9 16 61  3]
 [ 0  0  0  0  0]]
---------------------
KNN ==  9 :

0.659340659341
[[ 0  0  0  0]
 [ 0  0  0  0]
 [ 7 20 60  4]
 [ 0  0  0  0]]
---------------------
KNN ==  11 :

0.703296703297
[[ 0  0  0  0]
 [ 0  0  0  0]
 [ 4 19 64  4]
 [ 0  0  0  0]]
---------------------
KNN ==  13 :

0.681318681319
[[ 0  0  0  0]
 [ 0  0  0  0]
 [ 4 21 62  4]
 [ 0  0  0  0]]

******************************************************
SVM:
grid.fit
Fitting 3 folds for each of 90 candidates, totalling 270 fits
{'kernel': 'rbf', 'C': 32.0, 'gamma': 0.0001220703125}
SVC(C=32.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.0001220703125,
  kernel='rbf', max_iter=-1, probability=True, random_state=None,
  shrinking=True, tol=0.001, verbose=False)

0.714285714286

******************************************************
Perceptron:

0.89010989011
[[ 0  0  0]
 [ 8 81  2]
 [ 0  0  0]]

******************************************************
LDA:

0.714285714286
[[ 0  0  0]
 [20 65  6]
 [ 0  0  0]]

******************************************************
Logistic Regression - ovr:

0.714285714286
[[ 0  0  0  0]
 [ 0  0  0  0]
 [ 1 20 65  5]
 [ 0  0  0  0]]

******************************************************
Logistic Regression - mul:

0.692307692308
[[ 0  0  0  0]
 [ 0  0  0  0]
 [ 1 23 63  4]
 [ 0  0  0  0]]
######################################################
(5053, 4) (267, 4)

******************************************************
Decision Tree:

0.704119850187
[[  0   0   0   1   0]
 [  0   0   0  35   0]
 [  0   0   0  28   0]
 [  0   0   0 188   0]
 [  0   0   0  15   0]]

******************************************************
Gaussian Naive Bayes:

0.902621722846
[[  0   0   0   0]
 [  0   0   0   0]
 [  1  14 241  11]
 [  0   0   0   0]]

******************************************************
KNN:
---------------------
KNN ==  5 :

0.749063670412
[[  0   0   0   0   0]
 [  0   0   0   0   0]
 [  0   0   0   0   0]
 [  1  29  24 200  13]
 [  0   0   0   0   0]]
---------------------
KNN ==  9 :

0.767790262172
[[  0   0   0   0   0]
 [  0   0   0   0   0]
 [  0   0   0   0   0]
 [  1  22  19 205  20]
 [  0   0   0   0   0]]
---------------------
KNN ==  11 :

0.782771535581
[[  0   0   0   0   0]
 [  0   0   0   0   0]
 [  0   0   0   0   0]
 [  1  21  19 209  17]
 [  0   0   0   0   0]]
---------------------
KNN ==  13 :

0.786516853933
[[  0   0   0   0   0]
 [  0   0   0   0   0]
 [  0   0   0   0   0]
 [  1  14  18 210  24]
 [  0   0   0   0   0]]

******************************************************
SVM:
grid.fit
Fitting 3 folds for each of 90 candidates, totalling 270 fits
{'kernel': 'rbf', 'C': 8.0, 'gamma': 0.0001220703125}
SVC(C=8.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.0001220703125,
  kernel='rbf', max_iter=-1, probability=True, random_state=None,
  shrinking=True, tol=0.001, verbose=False)

0.838951310861

******************************************************
Perceptron:

0.0
[[  0   0   0   0]
 [  0   0   0   0]
 [  2 254   0  11]
 [  0   0   0   0]]

******************************************************
LDA:

0.801498127341
[[  0   0   0   0]
 [  0   0   0   0]
 [  5  28 214  20]
 [  0   0   0   0]]

******************************************************
Logistic Regression - ovr:

0.76404494382
[[  0   0   0   0]
 [  0   0   0   0]
 [  7  36 204  20]
 [  0   0   0   0]]

******************************************************
Logistic Regression - mul:

0.786516853933
[[  0   0   0   0]
 [  0   0   0   0]
 [  8  36 210  13]
 [  0   0   0   0]]
######################################################
(5268, 4) (52, 4)

******************************************************
Decision Tree:

0.173076923077
[[ 0  0  0  3  0]
 [ 0  0  0  8  0]
 [ 0  0  0 16  0]
 [ 0  0  0  9  0]
 [ 0  0  0 16  0]]

******************************************************
Gaussian Naive Bayes:

0.307692307692
[[ 0  0  0]
 [23 16 13]
 [ 0  0  0]]

******************************************************
KNN:
---------------------
KNN ==  5 :

0.153846153846
[[ 0  0  0  0]
 [ 0  0  0  0]
 [10 20  8 14]
 [ 0  0  0  0]]
---------------------
KNN ==  9 :

0.134615384615
[[ 0  0  0  0]
 [ 0  0  0  0]
 [ 9 20  7 16]
 [ 0  0  0  0]]
---------------------
KNN ==  11 :

0.115384615385
[[ 0  0  0  0]
 [ 0  0  0  0]
 [ 7 21  6 18]
 [ 0  0  0  0]]
---------------------
KNN ==  13 :

0.115384615385
[[ 0  0  0  0]
 [ 0  0  0  0]
 [ 6 22  6 18]
 [ 0  0  0  0]]

******************************************************
SVM:
grid.fit
Fitting 3 folds for each of 90 candidates, totalling 270 fits
{'kernel': 'rbf', 'C': 32.0, 'gamma': 0.0001220703125}
SVC(C=32.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.0001220703125,
  kernel='rbf', max_iter=-1, probability=True, random_state=None,
  shrinking=True, tol=0.001, verbose=False)

0.173076923077

******************************************************
Perceptron:

0.0384615384615
[[ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 6  4 37  2  3]
 [ 0  0  0  0  0]]

******************************************************
LDA:

0.211538461538
[[ 0  0  0  0]
 [ 0  0  0  0]
 [ 2 21 11 18]
 [ 0  0  0  0]]

******************************************************
Logistic Regression - ovr:

0.25
[[ 0  0  0  0]
 [ 0  0  0  0]
 [ 3 17 13 19]
 [ 0  0  0  0]]

******************************************************
Logistic Regression - mul:

0.192307692308
[[ 0  0  0  0]
 [ 0  0  0  0]
 [ 4 19 10 19]
 [ 0  0  0  0]]
######################################################
(5166, 4) (154, 4)

******************************************************
Decision Tree:

0.220779220779
[[ 0  0  0  0 53]
 [ 0  0  0  0 35]
 [ 0  0  0  0 31]
 [ 0  0  0  0  1]
 [ 0  0  0  0 34]]

******************************************************
Gaussian Naive Bayes:

0.0
[[  0   0   0   0]
 [  0   0   0   0]
 [  0   0   0   0]
 [130   1  23   0]]

******************************************************
KNN:
---------------------
KNN ==  5 :

0.175324675325
[[ 0  0  0  0]
 [ 0  0  0  0]
 [ 0  0  0  0]
 [72 31 24 27]]
---------------------
KNN ==  9 :

0.116883116883
[[ 0  0  0  0]
 [ 0  0  0  0]
 [ 0  0  0  0]
 [82 29 25 18]]
---------------------
KNN ==  11 :

0.149350649351
[[ 0  0  0  0]
 [ 0  0  0  0]
 [ 0  0  0  0]
 [85 26 20 23]]
---------------------
KNN ==  13 :

0.123376623377
[[ 0  0  0  0]
 [ 0  0  0  0]
 [ 0  0  0  0]
 [84 34 17 19]]

******************************************************
SVM:
grid.fit
Fitting 3 folds for each of 90 candidates, totalling 270 fits
{'kernel': 'rbf', 'C': 32.0, 'gamma': 0.0001220703125}
SVC(C=32.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.0001220703125,
  kernel='rbf', max_iter=-1, probability=True, random_state=None,
  shrinking=True, tol=0.001, verbose=False)

0.0779220779221

******************************************************
Perceptron:

0.0
[[  0   0   0]
 [  0   0   0]
 [  4 150   0]]

******************************************************
LDA:

0.0454545454545
[[  0   0   0]
 [  0   0   0]
 [117  30   7]]

******************************************************
Logistic Regression - ovr:

0.142857142857
[[ 0  0  0  0]
 [ 0  0  0  0]
 [ 0  0  0  0]
 [95 35  2 22]]

******************************************************
Logistic Regression - mul:

0.12987012987
[[ 0  0  0  0]
 [ 0  0  0  0]
 [ 0  0  0  0]
 [91 41  2 20]]
######################################################
(5259, 4) (61, 4)

******************************************************
Decision Tree:

0.196721311475
[[ 0  0  0  0  9]
 [ 0  0  0  0 21]
 [ 0  0  0  0 12]
 [ 0  0  0  0  7]
 [ 0  0  0  0 12]]

******************************************************
Gaussian Naive Bayes:

0.0983606557377
[[ 0  0  0  0]
 [ 0  0  0  0]
 [ 0  0  0  0]
 [13 36  6  6]]

******************************************************
KNN:
---------------------
KNN ==  5 :

0.295081967213
[[ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 6 21 12  4 18]]
---------------------
KNN ==  9 :

0.295081967213
[[ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 8 19 11  5 18]]
---------------------
KNN ==  11 :

0.327868852459
[[ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 7 18 12  4 20]]
---------------------
KNN ==  13 :

0.311475409836
[[ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 6 17 14  5 19]]

******************************************************
SVM:
grid.fit
Fitting 3 folds for each of 90 candidates, totalling 270 fits
{'kernel': 'rbf', 'C': 32.0, 'gamma': 0.0001220703125}
SVC(C=32.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.0001220703125,
  kernel='rbf', max_iter=-1, probability=True, random_state=None,
  shrinking=True, tol=0.001, verbose=False)

0.426229508197

******************************************************
Perceptron:

0.0327868852459
[[ 0  0  0  0]
 [ 0  0  0  0]
 [ 0  0  0  0]
 [ 2  4 53  2]]

******************************************************
LDA:

0.44262295082
[[ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [13 11  7  3 27]]

******************************************************
Logistic Regression - ovr:

0.459016393443
[[ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [12 12  5  4 28]]

******************************************************
Logistic Regression - mul:

0.459016393443
[[ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [11 14  5  3 28]]
######################################################
(5100, 4) (220, 4)

******************************************************
Decision Tree:

0.581818181818
[[  0   0   0   0   1]
 [  0   0   0   0  26]
 [  0   0   0   0  12]
 [  0   0   0   0  53]
 [  0   0   0   0 128]]

******************************************************
Gaussian Naive Bayes:

0.122727272727
[[  0   0   0]
 [  0   0   0]
 [ 75 118  27]]

******************************************************
KNN:
---------------------
KNN ==  5 :

0.668181818182
[[  0   0   0   0]
 [  0   0   0   0]
 [  0   0   0   0]
 [ 18  10  45 147]]
---------------------
KNN ==  9 :

0.690909090909
[[  0   0   0   0]
 [  0   0   0   0]
 [  0   0   0   0]
 [ 16  11  41 152]]
---------------------
KNN ==  11 :

0.681818181818
[[  0   0   0   0   0]
 [  0   0   0   0   0]
 [  0   0   0   0   0]
 [  0   0   0   0   0]
 [  1  13  11  45 150]]
---------------------
KNN ==  13 :

0.686363636364
[[  0   0   0   0]
 [  0   0   0   0]
 [  0   0   0   0]
 [ 10  10  49 151]]

******************************************************
SVM:
grid.fit
Fitting 3 folds for each of 90 candidates, totalling 270 fits
{'kernel': 'rbf', 'C': 32.0, 'gamma': 0.0001220703125}
SVC(C=32.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.0001220703125,
  kernel='rbf', max_iter=-1, probability=True, random_state=None,
  shrinking=True, tol=0.001, verbose=False)

0.731818181818

******************************************************
Perceptron:

0.8
[[  0   0   0]
 [  0   0   0]
 [  2  42 176]]

******************************************************
LDA:

0.759090909091
[[  0   0   0   0]
 [  0   0   0   0]
 [  0   0   0   0]
 [ 11   6  36 167]]

******************************************************
Logistic Regression - ovr:

0.718181818182
[[  0   0   0   0]
 [  0   0   0   0]
 [  0   0   0   0]
 [ 16   4  42 158]]

******************************************************
Logistic Regression - mul:

0.727272727273
[[  0   0   0   0]
 [  0   0   0   0]
 [  0   0   0   0]
 [ 16   4  40 160]]
######################################################
(5225, 4) (95, 4)

******************************************************
Decision Tree:

0.736842105263
[[ 0  0  0  8]
 [ 0  0  0 13]
 [ 0  0  0  4]
 [ 0  0  0 70]]

******************************************************
Gaussian Naive Bayes:

0.0947368421053
[[ 0  0  0]
 [ 0  0  0]
 [ 9 77  9]]

******************************************************
KNN:
---------------------
KNN ==  5 :

0.768421052632
[[ 0  0  0]
 [ 0  0  0]
 [ 5 17 73]]
---------------------
KNN ==  9 :

0.757894736842
[[ 0  0  0  0]
 [ 0  0  0  0]
 [ 0  0  0  0]
 [ 5 17  1 72]]
---------------------
KNN ==  11 :

0.789473684211
[[ 0  0  0]
 [ 0  0  0]
 [ 3 17 75]]
---------------------
KNN ==  13 :

0.768421052632
[[ 0  0  0]
 [ 0  0  0]
 [ 4 18 73]]

******************************************************
SVM:
grid.fit
Fitting 3 folds for each of 90 candidates, totalling 270 fits
{'kernel': 'rbf', 'C': 32.0, 'gamma': 0.0001220703125}
SVC(C=32.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.0001220703125,
  kernel='rbf', max_iter=-1, probability=True, random_state=None,
  shrinking=True, tol=0.001, verbose=False)

0.768421052632

******************************************************
Perceptron:

0.831578947368
[[ 0  0]
 [16 79]]

******************************************************
LDA:

0.821052631579
[[ 0  0  0]
 [ 0  0  0]
 [ 2 15 78]]

******************************************************
Logistic Regression - ovr:

0.873684210526
[[ 0  0]
 [12 83]]

******************************************************
Logistic Regression - mul:

0.852631578947
[[ 0  0  0]
 [ 0  0  0]
 [ 1 13 81]]
######################################################
(5088, 4) (232, 4)

******************************************************
Decision Tree:

0.487068965517
[[113   0   0   0]
 [ 54   0   0   0]
 [ 31   0   0   0]
 [ 34   0   0   0]]

******************************************************
Gaussian Naive Bayes:

0.956896551724
[[222  10]
 [  0   0]]

******************************************************
KNN:
---------------------
KNN ==  5 :

0.659482758621
[[153  42  19  18]
 [  0   0   0   0]
 [  0   0   0   0]
 [  0   0   0   0]]
---------------------
KNN ==  9 :

0.719827586207
[[167  35  10  20]
 [  0   0   0   0]
 [  0   0   0   0]
 [  0   0   0   0]]
---------------------
KNN ==  11 :

0.715517241379
[[166  37  10  19]
 [  0   0   0   0]
 [  0   0   0   0]
 [  0   0   0   0]]
---------------------
KNN ==  13 :

0.728448275862
[[169  31  12  20]
 [  0   0   0   0]
 [  0   0   0   0]
 [  0   0   0   0]]

******************************************************
SVM:
grid.fit
Fitting 3 folds for each of 90 candidates, totalling 270 fits
{'kernel': 'rbf', 'C': 32.0, 'gamma': 0.0001220703125}
SVC(C=32.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.0001220703125,
  kernel='rbf', max_iter=-1, probability=True, random_state=None,
  shrinking=True, tol=0.001, verbose=False)

0.784482758621

******************************************************
Perceptron:

0.327586206897
[[ 76  29  13 114]
 [  0   0   0   0]
 [  0   0   0   0]
 [  0   0   0   0]]

******************************************************
LDA:

0.853448275862
[[198  30   4]
 [  0   0   0]
 [  0   0   0]]

******************************************************
Logistic Regression - ovr:

0.711206896552
[[165  43  24]
 [  0   0   0]
 [  0   0   0]]

******************************************************
Logistic Regression - mul:

0.711206896552
[[165  44  23]
 [  0   0   0]
 [  0   0   0]]
######################################################
(5130, 4) (190, 4)

******************************************************
Decision Tree:

0.773684210526
[[147   0   0   0]
 [ 31   0   0   0]
 [  7   0   0   0]
 [  5   0   0   0]]

******************************************************
Gaussian Naive Bayes:

0.957894736842
[[182   2   6]
 [  0   0   0]
 [  0   0   0]]

******************************************************
KNN:
---------------------
KNN ==  5 :

0.921052631579
[[175  11   3   1]
 [  0   0   0   0]
 [  0   0   0   0]
 [  0   0   0   0]]
---------------------
KNN ==  9 :

0.942105263158
[[179   5   3   3]
 [  0   0   0   0]
 [  0   0   0   0]
 [  0   0   0   0]]
---------------------
KNN ==  11 :

0.942105263158
[[179   6   4   1]
 [  0   0   0   0]
 [  0   0   0   0]
 [  0   0   0   0]]
---------------------
KNN ==  13 :

0.947368421053
[[180   3   5   2]
 [  0   0   0   0]
 [  0   0   0   0]
 [  0   0   0   0]]

******************************************************
SVM:
grid.fit
Fitting 3 folds for each of 90 candidates, totalling 270 fits
{'kernel': 'rbf', 'C': 32.0, 'gamma': 0.0001220703125}
SVC(C=32.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.0001220703125,
  kernel='rbf', max_iter=-1, probability=True, random_state=None,
  shrinking=True, tol=0.001, verbose=False)

0.978947368421

******************************************************
Perceptron:

0.910526315789
[[173  15   2]
 [  0   0   0]
 [  0   0   0]]

******************************************************
LDA:

0.915789473684
[[174  16]
 [  0   0]]

******************************************************
Logistic Regression - ovr:

0.910526315789
[[173  17]
 [  0   0]]

******************************************************
Logistic Regression - mul:

0.936842105263
[[178  12]
 [  0   0]]
######################################################
(5277, 4) (43, 4)

******************************************************
Decision Tree:

0.139534883721
[[ 6  0  0  0  0]
 [ 2  0  0  0  0]
 [28  0  0  0  0]
 [ 5  0  0  0  0]
 [ 2  0  0  0  0]]

******************************************************
Gaussian Naive Bayes:

0.0
[[ 0 38  5]
 [ 0  0  0]
 [ 0  0  0]]

******************************************************
KNN:
---------------------
KNN ==  5 :

0.186046511628
[[ 8  1 30  2  2]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]
---------------------
KNN ==  9 :

0.0697674418605
[[ 3 34  4  2]
 [ 0  0  0  0]
 [ 0  0  0  0]
 [ 0  0  0  0]]
---------------------
KNN ==  11 :

0.046511627907
[[ 2 35  4  2]
 [ 0  0  0  0]
 [ 0  0  0  0]
 [ 0  0  0  0]]
---------------------
KNN ==  13 :

0.046511627907
[[ 2 35  4  2]
 [ 0  0  0  0]
 [ 0  0  0  0]
 [ 0  0  0  0]]

******************************************************
SVM:
grid.fit
Fitting 3 folds for each of 90 candidates, totalling 270 fits
{'kernel': 'rbf', 'C': 32.0, 'gamma': 0.0001220703125}
SVC(C=32.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.0001220703125,
  kernel='rbf', max_iter=-1, probability=True, random_state=None,
  shrinking=True, tol=0.001, verbose=False)

0.279069767442

******************************************************
Perceptron:

0.0
[[ 0 39  4]
 [ 0  0  0]
 [ 0  0  0]]

******************************************************
LDA:

0.0
[[ 0  1 35  2  5]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]

******************************************************
Logistic Regression - ovr:

0.0
[[ 0  1 31  3  8]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]

******************************************************
Logistic Regression - mul:

0.0
[[ 0  1 33  2  7]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  0  0]]
######################################################
(5217, 4) (103, 4)

******************************************************
Decision Tree:

0.466019417476
[[48  0  0  0]
 [13  0  0  0]
 [26  0  0  0]
 [16  0  0  0]]

******************************************************
Gaussian Naive Bayes:

0.932038834951
[[96  2  5]
 [ 0  0  0]
 [ 0  0  0]]

******************************************************
KNN:
---------------------
KNN ==  5 :

0.621359223301
[[64 11 14 14]
 [ 0  0  0  0]
 [ 0  0  0  0]
 [ 0  0  0  0]]
---------------------
KNN ==  9 :

0.592233009709
[[61  5 19 18]
 [ 0  0  0  0]
 [ 0  0  0  0]
 [ 0  0  0  0]]
---------------------
KNN ==  11 :

0.611650485437
[[63  5 17 18]
 [ 0  0  0  0]
 [ 0  0  0  0]
 [ 0  0  0  0]]
---------------------
KNN ==  13 :

0.640776699029
[[66  2 13 22]
 [ 0  0  0  0]
 [ 0  0  0  0]
 [ 0  0  0  0]]

******************************************************
SVM:
grid.fit
Fitting 3 folds for each of 90 candidates, totalling 270 fits
{'kernel': 'rbf', 'C': 32.0, 'gamma': 0.0001220703125}
SVC(C=32.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.0001220703125,
  kernel='rbf', max_iter=-1, probability=True, random_state=None,
  shrinking=True, tol=0.001, verbose=False)

0.708737864078

******************************************************
Perceptron:

0.0
[[  0 103]
 [  0   0]]

******************************************************
LDA:

0.893203883495
[[92 11]
 [ 0  0]]

******************************************************
Logistic Regression - ovr:

0.776699029126
[[80 15  4  4]
 [ 0  0  0  0]
 [ 0  0  0  0]
 [ 0  0  0  0]]

******************************************************
Logistic Regression - mul:

0.766990291262
[[79 15  4  5]
 [ 0  0  0  0]
 [ 0  0  0  0]
 [ 0  0  0  0]]
######################################################
######################################################
DT: 
[ 0.66071429  0.28282828  0.42307692  0.22929936  0.625       0.16551724
  0.44736842  0.76153846  0.57009346  0.56043956  0.70411985  0.17307692
  0.22077922  0.19672131  0.58181818  0.73684211  0.48706897  0.77368421
  0.13953488  0.46601942]
0.460277053344
gnb: 
[ 0.01785714  0.          0.02564103  0.          0.52083333  0.15862069
  0.70526316  0.61538462  0.99065421  0.8021978   0.90262172  0.30769231
  0.          0.09836066  0.12272727  0.09473684  0.95689655  0.95789474
  0.          0.93203883]
0.41047104486
knn: 
[ 0.66071429  0.57142857  0.55357143  0.41071429  0.2020202   0.17171717
  0.18686869  0.18181818  0.53846154  0.44871795  0.41025641  0.34615385
  0.27388535  0.20382166  0.17834395  0.1656051   0.71875     0.75
  0.73958333  0.75        0.12413793  0.08965517  0.06896552  0.06206897
  0.71578947  0.71052632  0.70526316  0.73684211  0.84615385  0.9
  0.89230769  0.89230769  0.69158879  0.69158879  0.74766355  0.76635514
  0.67032967  0.65934066  0.7032967   0.68131868  0.74906367  0.76779026
  0.78277154  0.78651685  0.15384615  0.13461538  0.11538462  0.11538462
  0.17532468  0.11688312  0.14935065  0.12337662  0.29508197  0.29508197
  0.32786885  0.31147541  0.66818182  0.69090909  0.68181818  0.68636364
  0.76842105  0.75789474  0.78947368  0.76842105  0.65948276  0.71982759
  0.71551724  0.72844828  0.92105263  0.94210526  0.94210526  0.94736842
  0.18604651  0.06976744  0.04651163  0.04651163  0.62135922  0.59223301
  0.61165049  0.6407767 ]
0.517749943271
9  =  0.514195207004
11  =  0.517428628345
5  =  0.531984577275
13  =  0.50739136046
svm: 
[ 0.71428571  0.15151515  0.34615385  0.15923567  0.77083333  0.08965517
  0.76315789  0.88461538  0.80373832  0.71428571  0.83895131  0.17307692
  0.07792208  0.42622951  0.73181818  0.76842105  0.78448276  0.97894737
  0.27906977  0.70873786]
0.558256650548
lda: 
[ 0.26785714  0.21212121  0.34615385  0.1656051   0.625       0.00689655
  0.74736842  0.83076923  0.60747664  0.71428571  0.80149813  0.21153846
  0.04545455  0.44262295  0.75909091  0.82105263  0.85344828  0.91578947
  0.          0.89320388]
0.513361655444
lr_ovr: 
[ 0.32142857  0.24747475  0.37179487  0.19745223  0.55208333  0.00689655
  0.62105263  0.79230769  0.70093458  0.71428571  0.76404494  0.25
  0.14285714  0.45901639  0.71818182  0.87368421  0.7112069   0.91052632
  0.          0.77669903]
0.506596383648
lr_mul: 
[ 0.30357143  0.26262626  0.37179487  0.13375796  0.63541667  0.00689655
  0.75789474  0.87692308  0.73831776  0.69230769  0.78651685  0.19230769
  0.12987013  0.45901639  0.72727273  0.85263158  0.7112069   0.93684211
  0.          0.76699029]
0.517108083755
